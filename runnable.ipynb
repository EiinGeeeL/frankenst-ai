{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOTE GRAPH: LangGraph Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.pregel.remote import RemoteGraph\n",
    "from langgraph_sdk import get_sync_client\n",
    "from langgraph.types import Command\n",
    "\n",
    "url = \"http://127.0.0.1:8000\"\n",
    "graph_name = \"main_graph\"\n",
    "sync_client = get_sync_client(url=url)\n",
    "remote_graph = RemoteGraph(graph_name, url=url)\n",
    "\n",
    "# create a thread (or use an existing thread instead)\n",
    "thread = sync_client.threads.create()\n",
    "\n",
    "# obtain the graph with the thread config\n",
    "config = {\"configurable\": {\"thread_id\": thread[\"thread_id\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input and invoke\n",
    "user_input = \"Ey, puedes resumirme 10 mensajes?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "for event in remote_graph.stream(message_input, config, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the action\n",
    "for event in remote_graph.stream(\n",
    "    # provide continue\n",
    "    Command(resume={\"action\": \"continue\"}),\n",
    "    config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOCAL AGENTS SERVERLESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OAKLANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from frank.workflow_builder import WorkflowBuilder\n",
    "from frank.config.layouts.simple_oak_config_graph import SimpleOakConfigGraph\n",
    "from frank.entity.models.stategraph import SharedState\n",
    "from frank.utils.common import read_yaml\n",
    "from frank.utils.logger import setup_logging\n",
    "from frank.constants import *\n",
    "\n",
    "## Read the config.yaml\n",
    "config = read_yaml(CONFIG_FILE_PATH)\n",
    "\n",
    "## Setup logging Configuration\n",
    "setup_logging(config)\n",
    "\n",
    "## Workflow Configuration for the main graph\n",
    "workflow_builder = WorkflowBuilder(\n",
    "    config=SimpleOakConfigGraph, \n",
    "    state_schema=SharedState, \n",
    "    checkpointer=MemorySaver(),\n",
    ")\n",
    "graph = workflow_builder.compile() # compile the graph\n",
    "workflow_builder.display_graph(save=True, filepath=\"artifacts/graph.png\") # update the graph artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RunnableConfig\n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "user_input = \"What is the evolution of feebas?; and could you give me random movements of the evolution?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HUMAN IN THE LOOP \n",
    "\n",
    "https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:54:12 - graph_layout - INFO - GraphLayout initialized\n",
      "2025-04-15 19:54:12 - edge_manager - INFO - EdgeManager initialized\n",
      "2025-04-15 19:54:12 - node_manager - INFO - NodeManager initialized\n",
      "2025-04-15 19:54:12 - workflow_builder - INFO - WorkFlowBuilder initialized\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from frank.workflow_builder import WorkflowBuilder\n",
    "from frank.config.layouts.oak_human_loop_config_graph import OakHumanLoopConfigGraph\n",
    "from frank.entity.models.stategraph import SharedState\n",
    "from frank.utils.common import read_yaml\n",
    "from frank.utils.logger import setup_logging\n",
    "from frank.constants import *\n",
    "\n",
    "## Read the config.yaml\n",
    "config = read_yaml(CONFIG_FILE_PATH)\n",
    "\n",
    "## Setup logging Configuration\n",
    "setup_logging(config)\n",
    "\n",
    "## Workflow Configuration for the main graph\n",
    "workflow_builder = WorkflowBuilder(\n",
    "    config=OakHumanLoopConfigGraph, \n",
    "    state_schema=SharedState, \n",
    "    checkpointer=MemorySaver(),\n",
    ")\n",
    "graph = workflow_builder.compile() # compile the graph\n",
    "# workflow_builder.display_graph(save=True, filepath=\"artifacts/human_graph.png\") # update the graph artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Define the RunnableConfig\n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO 1\n",
    "# Define the input\n",
    "user_input = \"Hi!\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "user_input = \"Could you give me random movements of pickachu, and what is his evolutions?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "user_input = \"I would like to capture all the pokemon of Ireland\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"feedback\", \n",
    "                                \"data\": \"Sorry, I just want to capture all the pokemon of Iceland... NOT IRELAND\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"continue\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix manage two calls in the same stage\n",
    "### DEMO 2\n",
    "# Define the input\n",
    "user_input = \"I would like to capture all the pokemon of Ireland. By the way... What is the latest evolution of Pikachu?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"feedback\", \n",
    "                                \"data\": \"Sorry, I just want to capture all the pokemon of Iceland... NOT IRELAND\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"continue\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Union\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from IPython.display import Image, display\n",
    "from services.llm import LLMServices\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from frank.components.tools.get_evolution_tool import GetEvolutionTool\n",
    "import requests\n",
    "\n",
    "\n",
    "@tool\n",
    "def weather_search(city: str):\n",
    "    \"\"\"Search for the weather\"\"\"\n",
    "    print(\"----\")\n",
    "    print(f\"Searching for: {city}\")\n",
    "    print(\"----\")\n",
    "    if city == 'New York':\n",
    "        return \"Sunny!\"\n",
    "    else:\n",
    "        return \"Cloudy\"\n",
    "\n",
    "# tools=[weather_search]\n",
    "tools=[GetEvolutionTool()]\n",
    "\n",
    "\n",
    "model = LLMServices.model.bind_tools(\n",
    "    tools\n",
    ")\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    \"\"\"Simple state.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "async def call_llm(state: Union[list[AnyMessage], dict[str, Any], BaseModel]) -> dict[str, list]:\n",
    "    messages = state[\"messages\"]\n",
    "    response = await model.ainvoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    print(f\"Printing Model State: {state}\")\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def human_review_node(state) -> Command[Literal[\"call_llm\", \"run_tool\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "\n",
    "    # if len(state[\"messages\"]) > 1:\n",
    "    #     prenultimate_message = state[\"messages\"][-1]\n",
    "    print(f\"HUMAN REVIEW NODE MESSAGES: {state[\"messages\"]}\")\n",
    "\n",
    "    # if type(state[\"messages\"][-2]) == AIMessage:\n",
    "    #     recent_message = state[\"messages\"][-2]\n",
    "    #     another_tool_call= recent_message.tools_calls[-2]\n",
    "\n",
    "\n",
    "    # this is the value we'll be providing via Command(resume=<human_review>)\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"run_tool\")\n",
    "\n",
    "    # update the AI message AND call tools\n",
    "    elif review_action == \"update\":\n",
    "        updated_message = {\n",
    "            \"role\": \"ai\",\n",
    "            \"content\": last_message.content,\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tool_call[\"id\"],\n",
    "                    \"name\": tool_call[\"name\"],\n",
    "                    # This the update provided by the human\n",
    "                    \"args\": review_data,\n",
    "                }\n",
    "            ],\n",
    "            # This is important - this needs to be the same as the message you replacing!\n",
    "            # Otherwise, it will show up as a separate message\n",
    "            \"id\": last_message.id,\n",
    "        }\n",
    "        return Command(goto=\"run_tool\", update={\"messages\": [updated_message]})\n",
    "\n",
    "    # provide feedback to LLM\n",
    "    elif review_action == \"feedback\":\n",
    "        # NOTE: we're adding feedback message as a ToolMessage\n",
    "        # to preserve the correct order in the message history\n",
    "        # (AI messages with tool calls need to be followed by tool call messages)\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            # This is our natural language feedback\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"call_llm\", update={\"messages\": [tool_message]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def route_after_llm(state) -> Literal[\"end\", \"review\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"review\"\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(call_llm)\n",
    "\n",
    "builder.add_node(ToolNode(tools=tools,\n",
    "         name=\"run_tool\"))\n",
    "\n",
    "builder.add_node(human_review_node)\n",
    "builder.add_edge(START, \"call_llm\")\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(source=\"call_llm\", \n",
    "                              path=route_after_llm,\n",
    "                              path_map={\n",
    "                                  \"end\": END, # If last call `tools`, then end.\n",
    "                                  \"review\": \"human_review_node\", # Human review in the loop.\n",
    "                                  }\n",
    ")\n",
    "\n",
    "builder.add_edge(\"run_tool\", \"call_llm\")\n",
    "\n",
    "# Set up memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Add\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# View\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Define the RunnableConfig\n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "user_input = \"Could you give the evolution of Feebas?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"feedback\", \n",
    "                                \"data\": \"Sorry, I just wanted to know the evolution of Pikachu\"})\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"update\", \n",
    "                                \"data\": {\"pokemon_name\": \"pikachu\"}})\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"continue\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# WHEATHER SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input\n",
    "user_input = \"Could you give the whether of LA?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"feedback\", \n",
    "                                \"data\": \"Sorry, I mean of New York\"})\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"update\", \n",
    "                                \"data\": {\"city\": \"New York\"}})\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_input = Command(resume={\"action\": \"continue\"})\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUTOGEN CORE + OAKLANG\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/framework/distributed-agent-runtime.html\n",
    "\n",
    "https://microsoft.github.io/autogen/stable/user-guide/core-user-guide/core-concepts/architecture.html\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "A distributed runtime, as shown in the diagram above, consists of a host servicer and multiple workers. The host servicer facilitates communication between agents across workers and maintains the states of connections. The workers run agents and communicate with the host servicer via gateways. They advertise to the host servicer the agents they run and manage the agentsâ€™ lifecycles.\n",
    "\n",
    "Agents work the same way as in the standalone runtime so that developers can switch between the two runtime types with no change to their agent implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOGEN WRAPPER\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "class LangGraphToolUseAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, graph: CompiledStateGraph) -> None:  # pyright: ignore\n",
    "        super().__init__(description)\n",
    "\n",
    "        # Use the graph builder compiled\n",
    "        self._app = graph\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        # Use the Runnable\n",
    "        final_state = await self._app.ainvoke(\n",
    "            {\n",
    "                \"messages\": [{\"role\": \"human\", \n",
    "                              \"content\": message.content}]\n",
    "            },\n",
    "            config=config, # RunnableConfig here\n",
    "        )\n",
    "        response = Message(content=final_state[\"messages\"][-1].content)\n",
    "        return response\n",
    "\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await LangGraphToolUseAgent.register(\n",
    "    runtime,\n",
    "    \"oaklang_langgraph\",\n",
    "    lambda: LangGraphToolUseAgent(\n",
    "        description=\"Tool use agent\",\n",
    "        graph=graph,\n",
    "    ),\n",
    ")\n",
    "agent = AgentId(\"oaklang_langgraph\", key=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime.start()\n",
    "response = await runtime.send_message(Message(\"What is the evolution of feebas?; and could you give me random movements of the evolution?\"), agent)\n",
    "print(response.content)\n",
    "await runtime.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUTOGEN + OAKLANG + HUMAN IN THE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from typing import Union\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from langgraph.types import Command  \n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "\n",
    "@dataclass\n",
    "class WrapperCommand(BaseModel):\n",
    "    command: Command\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "\n",
    "class LangGraphToolUseAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, graph: CompiledStateGraph) -> None:\n",
    "        super().__init__(description)\n",
    "        self._app = graph\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_user_message(self, message: Union[Message, WrapperCommand], ctx: MessageContext) -> Message:\n",
    "        # Build input for astream depending on message type\n",
    "        if isinstance(message, Message):\n",
    "            input_data = {\"messages\": [{\"role\": \"human\", \"content\": message.content}]}\n",
    "        elif isinstance(message, WrapperCommand):\n",
    "            input_data = message.command\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported message type\")\n",
    "\n",
    "        output = \"\"\n",
    "        async for event in self._app.astream(input_data, config, stream_mode=\"updates\"):\n",
    "            print(\"Event streamed:\", event)\n",
    "            if isinstance(event, dict) and \"messages\" in event:\n",
    "                last_msg = event[\"messages\"][-1][\"content\"]\n",
    "                output = last_msg  # Capture the latest content\n",
    "\n",
    "        return Message(content=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from typing import Optional\n",
    "from langgraph.types import Command  \n",
    "\n",
    "class Message(BaseModel):\n",
    "    content: Optional[str] = None\n",
    "    command: Optional[Command] = None\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "class LangGraphToolUseAgent(RoutedAgent):\n",
    "    def __init__(self, description: str, graph: CompiledStateGraph) -> None:\n",
    "        super().__init__(description)\n",
    "        self._app = graph\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        if message.command is not None:\n",
    "            input_data = message.command\n",
    "        else:\n",
    "            input_data = {\"messages\": [{\"role\": \"human\", \"content\": message.content}]}\n",
    "\n",
    "        output = \"\"\n",
    "\n",
    "        async for event in self._app.astream(input_data, config, stream_mode=\"updates\"):\n",
    "            print(\"Message stream event:\", event)\n",
    "            if isinstance(event, dict) and \"messages\" in event:\n",
    "                output = event[\"messages\"][-1][\"content\"]\n",
    "\n",
    "        return Message(content=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await LangGraphToolUseAgent.register(\n",
    "    runtime,\n",
    "    \"oaklang_langgraph\",\n",
    "    lambda: LangGraphToolUseAgent(\n",
    "        description=\"Tool use agent\",\n",
    "        graph=graph,\n",
    "    ),\n",
    ")\n",
    "agent = AgentId(\"oaklang_langgraph\", key=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:54:28 - autogen_core - INFO - Calling message handler for oaklang_langgraph/default with message type Message sent by Unknown\n",
      "2025-04-15 19:54:28 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"I want capture all pokemon of Ireland\\\",\\\"command\\\":null}\", \"sender\": null, \"receiver\": \"oaklang_langgraph/default\", \"kind\": \"MessageKind.DIRECT\", \"delivery_stage\": \"DeliveryStage.DELIVER\", \"type\": \"Message\"}\n",
      "2025-04-15 19:54:28 - azure.core.pipeline.policies.http_logging_policy - INFO - Request URL: 'https://myaifoundrytra9200989372.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '1334'\n",
      "    'Accept': 'application/json'\n",
      "    'x-ms-client-request-id': 'acebf515-1a22-11f0-b223-00155dd0047e'\n",
      "    'api-key': 'REDACTED'\n",
      "    'User-Agent': 'langchain-azure-ai azsdk-python-ai-inference/1.0.0b9 Python/3.12.3 (Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "2025-04-15 19:54:28 - azure.core.pipeline.policies.http_logging_policy - INFO - Response status: 200\n",
      "Response headers:\n",
      "    'Content-Length': '1046'\n",
      "    'Content-Type': 'application/json'\n",
      "    'apim-request-id': 'REDACTED'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'x-content-type-options': 'REDACTED'\n",
      "    'x-ms-region': 'REDACTED'\n",
      "    'x-ratelimit-remaining-requests': 'REDACTED'\n",
      "    'x-ratelimit-limit-requests': 'REDACTED'\n",
      "    'x-ratelimit-remaining-tokens': 'REDACTED'\n",
      "    'x-ratelimit-limit-tokens': 'REDACTED'\n",
      "    'cmp-upstream-response-duration': 'REDACTED'\n",
      "    'x-accel-buffering': 'REDACTED'\n",
      "    'x-aml-cluster': 'REDACTED'\n",
      "    'x-envoy-upstream-service-time': 'REDACTED'\n",
      "    'x-ms-rai-invoked': 'REDACTED'\n",
      "    'x-request-id': 'REDACTED'\n",
      "    'ms-azureml-model-time': 'REDACTED'\n",
      "    'x-ms-client-request-id': 'acebf515-1a22-11f0-b223-00155dd0047e'\n",
      "    'azureml-model-session': 'REDACTED'\n",
      "    'x-ms-deployment-name': 'REDACTED'\n",
      "    'Date': 'Tue, 15 Apr 2025 17:54:28 GMT'\n",
      "Message stream event: {'OakLangAgent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}}]}, response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}, 'finish_reason': 'tool_calls'}, id='run-a1ce6564-5742-4ff2-83ea-e03d623b1f26-0', tool_calls=[{'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214})]}}\n",
      "############STATE: {'messages': [HumanMessage(content='I want capture all pokemon of Ireland', additional_kwargs={}, response_metadata={}, id='969777c6-a33d-4fd9-919d-289bd7bed7d8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}}]}, response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}, 'finish_reason': 'tool_calls'}, id='run-a1ce6564-5742-4ff2-83ea-e03d623b1f26-0', tool_calls=[{'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214})]}\n",
      "############LAST_MESSAGE: content='' additional_kwargs={'tool_calls': [{'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}}]} response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}, 'finish_reason': 'tool_calls'} id='run-a1ce6564-5742-4ff2-83ea-e03d623b1f26-0' tool_calls=[{'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}] usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}\n",
      "################TOOLS CALL: {'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}\n",
      "Message stream event: {'__interrupt__': (Interrupt(value={'question': 'Are you sure to make that pokemon senstivie action to Ireland?', 'tool_call': {'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}}, resumable=True, ns=['human_review:44bac6aa-78df-83a4-4e95-df1f4a063f5d']),)}\n",
      "2025-04-15 19:54:28 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"\\\",\\\"command\\\":null}\", \"sender\": \"oaklang_langgraph/default\", \"receiver\": null, \"kind\": \"MessageKind.RESPOND\", \"delivery_stage\": \"DeliveryStage.SEND\", \"type\": \"Message\"}\n",
      "2025-04-15 19:54:28 - autogen_core - INFO - Resolving response with message type Message for recipient None from oaklang_langgraph: {'content': '', 'command': None}\n",
      "2025-04-15 19:54:28 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"\\\",\\\"command\\\":null}\", \"sender\": \"oaklang_langgraph/default\", \"receiver\": null, \"kind\": \"MessageKind.RESPOND\", \"delivery_stage\": \"DeliveryStage.DELIVER\", \"type\": \"Message\"}\n",
      "2025-04-15 19:55:19 - autogen_core - INFO - Calling message handler for oaklang_langgraph/default with message type Message sent by Unknown\n",
      "2025-04-15 19:55:19 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":null,\\\"command\\\":{\\\"graph\\\":null,\\\"update\\\":null,\\\"resume\\\":{\\\"action\\\":\\\"continue\\\"},\\\"goto\\\":[]}}\", \"sender\": null, \"receiver\": \"oaklang_langgraph/default\", \"kind\": \"MessageKind.DIRECT\", \"delivery_stage\": \"DeliveryStage.DELIVER\", \"type\": \"Message\"}\n",
      "############STATE: {'messages': [HumanMessage(content='I want capture all pokemon of Ireland', additional_kwargs={}, response_metadata={}, id='969777c6-a33d-4fd9-919d-289bd7bed7d8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}}]}, response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}, 'finish_reason': 'tool_calls'}, id='run-a1ce6564-5742-4ff2-83ea-e03d623b1f26-0', tool_calls=[{'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214})]}\n",
      "############LAST_MESSAGE: content='' additional_kwargs={'tool_calls': [{'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}}]} response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}, 'finish_reason': 'tool_calls'} id='run-a1ce6564-5742-4ff2-83ea-e03d623b1f26-0' tool_calls=[{'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}] usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214}\n",
      "################TOOLS CALL: {'name': 'DominatePokemonTool', 'args': {'place': 'Ireland'}, 'id': 'call_772DzYeB0mzkF3OlAsDNp1wG', 'type': 'tool_call'}\n",
      "Message stream event: {'human_review': None}\n",
      "2025-04-15 19:55:19 - dominate_pokemon_tool - INFO - Args: Ireland\n",
      "Message stream event: {'OakTools': {'messages': [ToolMessage(content='https://www.youtube.com/watch?v=dQw4w9WgXcQ', name='DominatePokemonTool', id='89622a26-6ff3-4c06-b74c-1986cc1deeea', tool_call_id='call_772DzYeB0mzkF3OlAsDNp1wG')]}}\n",
      "2025-04-15 19:55:19 - azure.core.pipeline.policies.http_logging_policy - INFO - Request URL: 'https://myaifoundrytra9200989372.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=REDACTED'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '1691'\n",
      "    'Accept': 'application/json'\n",
      "    'x-ms-client-request-id': 'cb8afceb-1a22-11f0-84bb-00155dd0047e'\n",
      "    'api-key': 'REDACTED'\n",
      "    'User-Agent': 'langchain-azure-ai azsdk-python-ai-inference/1.0.0b9 Python/3.12.3 (Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39)'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "2025-04-15 19:55:20 - azure.core.pipeline.policies.http_logging_policy - INFO - Response status: 200\n",
      "Response headers:\n",
      "    'Content-Length': '1458'\n",
      "    'Content-Type': 'application/json'\n",
      "    'apim-request-id': 'REDACTED'\n",
      "    'Strict-Transport-Security': 'REDACTED'\n",
      "    'x-content-type-options': 'REDACTED'\n",
      "    'x-ms-region': 'REDACTED'\n",
      "    'x-ratelimit-remaining-requests': 'REDACTED'\n",
      "    'x-ratelimit-limit-requests': 'REDACTED'\n",
      "    'x-ratelimit-remaining-tokens': 'REDACTED'\n",
      "    'x-ratelimit-limit-tokens': 'REDACTED'\n",
      "    'cmp-upstream-response-duration': 'REDACTED'\n",
      "    'x-accel-buffering': 'REDACTED'\n",
      "    'x-aml-cluster': 'REDACTED'\n",
      "    'x-envoy-upstream-service-time': 'REDACTED'\n",
      "    'x-ms-rai-invoked': 'REDACTED'\n",
      "    'x-request-id': 'REDACTED'\n",
      "    'ms-azureml-model-time': 'REDACTED'\n",
      "    'x-ms-client-request-id': 'cb8afceb-1a22-11f0-84bb-00155dd0047e'\n",
      "    'azureml-model-session': 'REDACTED'\n",
      "    'x-ms-deployment-name': 'REDACTED'\n",
      "    'Date': 'Tue, 15 Apr 2025 17:55:21 GMT'\n",
      "Message stream event: {'OakLangAgent': {'messages': [AIMessage(content=\"To help you capture all the PokÃ©mon in Ireland, I've set a plan in motion! You can check out this video for the exciting effects of that action: [Watch Here](https://www.youtube.com/watch?v=dQw4w9WgXcQ). Best of luck on your journey to become a PokÃ©mon Master!\", additional_kwargs={}, response_metadata={'model': 'gpt-4o-mini-2024-07-18', 'token_usage': {'input_tokens': 241, 'output_tokens': 68, 'total_tokens': 309}, 'finish_reason': 'stop'}, id='run-38967149-6793-4583-86f6-5ace37c006c8-0', usage_metadata={'input_tokens': 241, 'output_tokens': 68, 'total_tokens': 309})]}}\n",
      "2025-04-15 19:55:20 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"\\\",\\\"command\\\":null}\", \"sender\": \"oaklang_langgraph/default\", \"receiver\": null, \"kind\": \"MessageKind.RESPOND\", \"delivery_stage\": \"DeliveryStage.SEND\", \"type\": \"Message\"}\n",
      "2025-04-15 19:55:20 - autogen_core - INFO - Resolving response with message type Message for recipient None from oaklang_langgraph: {'content': '', 'command': None}\n",
      "2025-04-15 19:55:20 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"\\\",\\\"command\\\":null}\", \"sender\": \"oaklang_langgraph/default\", \"receiver\": null, \"kind\": \"MessageKind.RESPOND\", \"delivery_stage\": \"DeliveryStage.DELIVER\", \"type\": \"Message\"}\n"
     ]
    }
   ],
   "source": [
    "# Start the runtime\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with regular message\n",
    "response = await runtime.send_message(\n",
    "    Message(content=\"What is the evolution of feebas?; and could you give me random movements of the evolution?\", command=None),\n",
    "    agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:54:28 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":\\\"I want capture all pokemon of Ireland\\\",\\\"command\\\":null}\", \"sender\": null, \"receiver\": \"oaklang_langgraph/default\", \"kind\": \"MessageKind.DIRECT\", \"delivery_stage\": \"DeliveryStage.SEND\", \"type\": \"Message\"}\n",
      "2025-04-15 19:54:28 - autogen_core - INFO - Sending message of type Message to oaklang_langgraph: {'content': 'I want capture all pokemon of Ireland', 'command': None}\n"
     ]
    }
   ],
   "source": [
    "# Example with regular message\n",
    "response = await runtime.send_message(\n",
    "    Message(content='I want capture all pokemon of Ireland', command=None),\n",
    "    agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-15 19:55:19 - autogen_core.events - INFO - {\"payload\": \"{\\\"content\\\":null,\\\"command\\\":{\\\"graph\\\":null,\\\"update\\\":null,\\\"resume\\\":{\\\"action\\\":\\\"continue\\\"},\\\"goto\\\":[]}}\", \"sender\": null, \"receiver\": \"oaklang_langgraph/default\", \"kind\": \"MessageKind.DIRECT\", \"delivery_stage\": \"DeliveryStage.SEND\", \"type\": \"Message\"}\n",
      "2025-04-15 19:55:19 - autogen_core - INFO - Sending message of type Message to oaklang_langgraph: {'content': None, 'command': Command(resume={'action': 'continue'})}\n"
     ]
    }
   ],
   "source": [
    "# Example with regular message\n",
    "response = await runtime.send_message(\n",
    "    Message(content=None, command=Command(resume={\"action\": \"continue\"})),\n",
    "    agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with regular message\n",
    "response = await runtime.send_message(\n",
    "    Message(content=None, command=Command(resume={\"action\": \"feedback\", \"data\": \"Sorry, I just want to capture all the pokemon of Iceland... NOT IRELAND\"})),\n",
    "    agent\n",
    ")\n",
    "\n",
    "# # Example with command message\n",
    "# response = await runtime.send_message(\n",
    "#     Command(resume={\"action\": \"feedback\", \"data\": \"Sorry, I just want to capture all the pokemon of Iceland... NOT IRELAND\"}),\n",
    "#     agent\n",
    "# )\n",
    "# print(\"Response:\", response.content)\n",
    "\n",
    "# # Stop the runtime\n",
    "# await runtime.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with command message\n",
    "response = await runtime.send_message(\n",
    "    WrapperCommand(Command(resume={\"action\": \"feedback\", \"data\": \"Sorry, I just want to capture all the pokemon of Iceland... NOT IRELAND\"})),\n",
    "    agent\n",
    ")\n",
    "print(\"Response:\", response.command)\n",
    "\n",
    "# Stop the runtime\n",
    "await runtime.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AZURE AI FOUNDRY TRACE MONITORING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRACE MONITORING AUTOGEN + LANGGRAPH (NATIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/langchain\n",
    "\n",
    "#A\n",
    "import os\n",
    "\n",
    "application_insights_connection_string = os.environ[\"AZURE_APP_INSIGHT_CONNECTION_STRING\"]\n",
    "\n",
    "#B\n",
    "\n",
    "# from azure.ai.projects import AIProjectClient\n",
    "# from azure.identity import DefaultAzureCredential # NOTE USE ASYNC DEFAULT CREDENTIALS\n",
    "\n",
    "# project_client = AIProjectClient.from_connection_string(\n",
    "#     credential=DefaultAzureCredential(),\n",
    "#     conn_str=\"<your-project-connection-string>\",\n",
    "# )\n",
    "\n",
    "# application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "\n",
    "\n",
    "from langchain_azure_ai.callbacks.tracers import AzureAIInferenceTracer\n",
    "\n",
    "langchain_tracer = AzureAIInferenceTracer(\n",
    "    connection_string=application_insights_connection_string,\n",
    "    enable_content_recording=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}, \"callbacks\": [langchain_tracer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LANGGRAPH\n",
    "\n",
    "# Define the input\n",
    "user_input = \"What is the evolution of feebas?; and could you give me random movements of the evolution?\"\n",
    "message_input = {\"messages\": [{\"role\": \"human\", \"content\": user_input}]}\n",
    "\n",
    "# Asynchronous function to handle the async generator\n",
    "async def process_stream():\n",
    "    async for event in graph.astream(message_input, config, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Directly await the function if you're in a notebook or similar environment\n",
    "await process_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOGEN WRAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOGEN + LANGGRAPH\n",
    "runtime.start()\n",
    "response = await runtime.send_message(Message(\"What is the evolution of feebas?; and could you give me random movements of the evolution?\"), agent)\n",
    "print(response.content)\n",
    "await runtime.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRACE MONITORING AUTOGEN + LANGGRAPH (NATIVE AND NESTED)\n",
    "\n",
    "\n",
    "When AIInferenceInstrumentor and AzureAIInferenceTracer are both enabled, there are running into issues like:\n",
    "\n",
    "* Context mismatch: spans not appearing under the correct parent.\n",
    "\n",
    "* Span duplication: multiple root spans instead of nested ones.\n",
    "\n",
    "* Runtime errors: likely related to uninstrumented or mismatched spans.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/langchain\n",
    "\n",
    "#A\n",
    "import os\n",
    "\n",
    "application_insights_connection_string = os.environ[\"AZURE_APP_INSIGHT_CONNECTION_STRING\"]\n",
    "\n",
    "#B\n",
    "\n",
    "# from azure.ai.projects import AIProjectClient\n",
    "# from azure.identity import DefaultAzureCredential # NOTE USE ASYNC DEFAULT CREDENTIALS\n",
    "\n",
    "# project_client = AIProjectClient.from_connection_string(\n",
    "#     credential=DefaultAzureCredential(),\n",
    "#     conn_str=\"<your-project-connection-string>\",\n",
    "# )\n",
    "\n",
    "# application_insights_connection_string = project_client.telemetry.get_connection_string()\n",
    "\n",
    "\n",
    "from langchain_azure_ai.callbacks.tracers import AzureAIInferenceTracer\n",
    "\n",
    "langchain_tracer = AzureAIInferenceTracer(\n",
    "    connection_string=application_insights_connection_string,\n",
    "    enable_content_recording=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the thread_id\n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}, \"callbacks\": [langchain_tracer]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOGEN WRAPPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from opentelemetry import trace\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from azure.ai.inference.tracing import AIInferenceInstrumentor \n",
    "from opentelemetry.instrumentation.threading import ThreadingInstrumentor\n",
    "\n",
    "# NOTE: Already made in LangCHain\n",
    "# Enable Azure Monitor tracing\n",
    "# application_insights_connection_string = os.environ[\"AZURE_APP_INSIGHT_CONNECTION_STRING\"]\n",
    "# configure_azure_monitor(connection_string=application_insights_connection_string)\n",
    "\n",
    "# ThreadingInstrumentor().instrument(enable_content_recording=True)\n",
    "# instrumentor = AIInferenceInstrumentor() \n",
    "# instrumentor.instrument(enable_content_recording=True) \n",
    "\n",
    "scenario = \"autogen_langgraph_trace_monitoring_nested\" # os.path.basename(__file__)\n",
    "tracer = trace.get_tracer(__name__)\n",
    "\n",
    "\n",
    "with tracer.start_as_current_span(scenario) as parent_span:\n",
    "    runtime.start()\n",
    "    response = await runtime.send_message(Message(\"What is the evolution of feebas?; and could you give me random movements of the evolution?\"), agent)\n",
    "    print(response.content)\n",
    "    await runtime.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– LangGraph + AutoGen: Resumen\n",
    "\n",
    "## ðŸ§  Â¿QuÃ© aporta cada uno?\n",
    "\n",
    "### âœ… Ventajas de usar AutoGen con LangGraph\n",
    "\n",
    "**AutoGen destaca por:**\n",
    "- GestiÃ³n de mÃºltiples agentes con roles definidos (`user_proxy`, `assistant`, `coder`, `critic`, etc.).\n",
    "- Supervisor integrado para coordinar agentes automÃ¡ticamente.\n",
    "- Soporte para memoria, mÃºltiples rondas y auto-detenciÃ³n.\n",
    "- Ideal como \"orquestadora\" de agentes sobre un backend.\n",
    "\n",
    "**LangGraph destaca por:**\n",
    "- Flujos **determinÃ­sticos y controlables** mediante nodos y condiciones.\n",
    "- Ideal para workflows estructurados, decisiones condicionales y visualizaciÃ³n.\n",
    "- Cada nodo puede representar un paso lÃ³gico o un agente.\n",
    "\n",
    "---\n",
    "\n",
    "## Â¿DÃ³nde es mejor ubicar un **supervisor**?\n",
    "\n",
    "### OpciÃ³n 1: **Supervisor en AutoGen**\n",
    "\n",
    "**âœ… Pros:**\n",
    "- Implementado por defecto.\n",
    "- Maneja decisiones reflexivas y coordinaciÃ³n entre agentes.\n",
    "- Bueno para agentes que necesitan interactuar dinÃ¡micamente.\n",
    "\n",
    "**âŒ Contras:**\n",
    "- Menos control estructural del flujo.\n",
    "- MÃ¡s difÃ­cil de visualizar o predecir.\n",
    "\n",
    "### OpciÃ³n 2: **Supervisor en LangGraph**\n",
    "\n",
    "**âœ… Pros:**\n",
    "- Control total del flujo, decisiones, loops y bifurcaciones.\n",
    "- FÃ¡cil de visualizar y depurar.\n",
    "\n",
    "**âŒ Contras:**\n",
    "- Tienes que codificar la lÃ³gica supervisora manualmente.\n",
    "- Menos dinÃ¡mico que AutoGen en colaboraciÃ³n espontÃ¡nea.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Â¿QuÃ© hacer si quiero mÃ¡s agentes y un supervisor personalizado?\n",
    "\n",
    "### ðŸ› ï¸ OpciÃ³n 1: LangGraph como estructura principal\n",
    "\n",
    "- Crea un nodo \"supervisor\" que decide quÃ© agente activar.\n",
    "- Cada agente es un nodo con lÃ³gica definida.\n",
    "- Ideal para sistemas robustos y predecibles.\n",
    "\n",
    "### ðŸ¤ OpciÃ³n 2: AutoGen como coordinador de alto nivel\n",
    "\n",
    "- AutoGen se encarga del flujo y supervisiÃ³n.\n",
    "- LangGraph se usa dentro de ciertos agentes como motor de flujo interno.\n",
    "- Ideal si necesitas colaboraciÃ³n y razonamiento multiagente.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Œ Key Points\n",
    "\n",
    "- Si quieres **colaboraciÃ³n reflexiva y automatizada** â†’ usa el **supervisor de AutoGen**.\n",
    "- Si quieres **control total del flujo y reglas personalizadas** â†’ implementa el **supervisor en LangGraph**.\n",
    "- Para lo mejor de ambos mundos: **usa LangGraph como estructura y AutoGen como capa de decisiÃ³n/reflexiÃ³n.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
