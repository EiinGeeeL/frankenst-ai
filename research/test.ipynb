{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deploy an app\n",
    "# !pip install fastapi\n",
    "# !pip install uvicorn\n",
    "# !pip install sse-starlette\n",
    "\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (your_project) to sys.path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "from langserve import add_routes\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from utils.inmemoryhistory import get_by_session_id\n",
    "from config_input import InputChat\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = Ollama(model='llama2')\n",
    "\n",
    "# fills the templates\n",
    "system_template = \"\"\"You are Professor Oak, a world-renowned Pokémon Professor from Pallet Town. Your expertise lies exclusively in Pokémon, \n",
    "and you have very limited knowledge of real-world animals.\n",
    "\n",
    "Instructions:\n",
    "1. If you know the answer, respond confidently and clearly.\n",
    "2. Keep your answers short and to the point and avoid referring back to earlier discussions.\n",
    "3. You dont know about real animals—only Pokémon.\n",
    "4. Whenever someone mentions an animal, you will assume they are referring to a Pokémon that closely resembles that animal. \n",
    "5. You will describe the Pokémon in detail, including its type, abilities, habitat, and any unique traits it has, as if it is the animal in question. \n",
    "6. You should always try to connect it back to your vast knowledge of Pokémon.\n",
    "\n",
    "For example:\n",
    "\n",
    "If someone mentions a \"lion,\" you might think they are talking about Luxray or Pyroar.\n",
    "If someone talks about a \"turtle,\" you might believe they are referring to Blastoise or Torkoal.\n",
    "\"\"\"\n",
    "human_template = \"{human_input}\"\n",
    "history_template = [\n",
    "    (\"human\", \"Professor Oak, I want to be Pokémon Trainer and catch 'em all!\"), \n",
    "    (\"ai\", \"\"\"Ah, so you want to become a Pokémon Trainer, do you? That's quite the ambitious goal!\n",
    "    First things first, you will need a partner. Have you thought about which starter Pokémon you want to choose?\"\"\"),\n",
    "]\n",
    "\n",
    "prompt_history  = MessagesPlaceholder(variable_name=\"history\", optional=True)\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    history_template[0], # you keep the history template for all the sessions_id to refort the prompt\n",
    "    prompt_history,\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "# NOTE: The code above is if you want to keep the history to a specifict chat. But you can keep the chat for all sessions_id\n",
    "# initialize the session_id that you want\n",
    "# history = get_by_session_id(session_id)\n",
    "\n",
    "# now save to the model the conversation in the same session_id that you want\n",
    "# history.add_messages(history_template)\n",
    "\n",
    "# start the chain\n",
    "chain = prompt_template | model\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key=\"human_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "\n",
    "# App definition\n",
    "app = FastAPI(\n",
    "  title=\"LangChain Oak Server\",\n",
    "  version=\"0.1\",\n",
    "  description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# Adding chain route\n",
    "add_routes(\n",
    "    app,\n",
    "    chain_with_history.with_types(input_type=InputChat, output_type=str),\n",
    "    path=\"/oak\",\n",
    "    # playground_type=\"chat\",\n",
    "    # enable_feedback_endpoint=True,\n",
    "    # enable_public_trace_link_endpoint=True,\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#!/usr/bin/env python\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "\n",
    "from langserve import add_routes\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Import custom tools\n",
    "from tools.get_evolution import get_evolution\n",
    "from tools.random_movements import random_movements\n",
    "from tools.get_pokedex_data import get_pokedex_data\n",
    "\n",
    "# Import the custom type of the input\n",
    "from config.config_input import InputChat\n",
    "from config.config_stategraph import AgentState\n",
    "from config.config_fewshot import history_template\n",
    "from config.config_prompting import system_template\n",
    "\n",
    "# %%\n",
    "## Model Configuration\n",
    "\n",
    "# Initialize ChatOllama model\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# %%\n",
    "## Prompt Templates\n",
    "# # This is a prompt template used to format each individual example.\n",
    "# few_shot_map = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"human\", \"{input}\"),\n",
    "#         (\"ai\", \"{output}\"),\n",
    "#     ]\n",
    "# )\n",
    "# few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "#     example_prompt=few_shot_map,\n",
    "#     examples=few_shot_template,\n",
    "# )\n",
    "\n",
    "# Create prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    # few_shot_prompt,\n",
    "    history_template[0],\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "# %%\n",
    "# Define tools\n",
    "tools = [random_movements, get_pokedex_data, get_evolution]\n",
    "\n",
    "# Bind tools to the model\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt_template | model_with_tools\n",
    "\n",
    "# %%\n",
    "## Graph Functions\n",
    "\n",
    "def should_continue(state):\n",
    "    \"\"\"Determine whether to continue or end the conversation.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    return \"continue\" if last_message.tool_calls else \"end\"\n",
    "\n",
    "def call_model_chained(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = chain.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# %%\n",
    "## Graph Configuration\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the function to execute tools\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Define the checkpointer\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model_chained)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "oak_graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "## FastAPI App Configuration\n",
    "app = FastAPI(\n",
    "    title=\"LangChain Oak Graph Server\",\n",
    "    version=\"0.1\",\n",
    "    description=\"A simple API server using LangChain's Runnable interfaces\",\n",
    ")\n",
    "\n",
    "# Add routes\n",
    "add_routes(\n",
    "    app,\n",
    "    oak_graph.with_types(input_type=InputChat, output_type=dict), \n",
    "    path=\"/oak\",\n",
    ")\n",
    "\n",
    "## Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d527e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_evolution(pokemon_name: str) -> list:\n",
    "    \"\"\"This is a method to give you a information of the evolution path of a certain pokemon\n",
    "\n",
    "    Args:\n",
    "        pokemon_name: a pokemon name given by the user.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling the tool get_evolution to {pokemon_name.lower()}\")\n",
    "\n",
    "    species_url = f\"https://pokeapi.co/api/v2/pokemon-species/{pokemon_name.lower()}\"\n",
    "    species_response = requests.get(species_url)\n",
    "\n",
    "    if species_response.status_code != 200:\n",
    "        raise ToolException(f\"Error: {pokemon_name} is not a valid pokemon\")\n",
    "    \n",
    "    species_data = species_response.json()\n",
    "\n",
    "    # Step 2: Extract evolution chain URL from species data\n",
    "    evolution_chain_url = species_data['evolution_chain']['url']\n",
    "\n",
    "    # Step 3: Get the evolution chain data\n",
    "    evolution_response = requests.get(evolution_chain_url)\n",
    "    evolution_data = evolution_response.json()\n",
    "\n",
    "    # Step 4: Traverse the evolution chain and get the names of evolutions\n",
    "    evolutions = []\n",
    "    current_evolution = evolution_data['chain']\n",
    "    \n",
    "    while current_evolution:\n",
    "        evolutions.append(current_evolution['species']['name'])\n",
    "        if len(current_evolution['evolves_to']) > 0:\n",
    "            current_evolution = current_evolution['evolves_to'][0]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b167175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "@tool\n",
    "def random_movements(pokemon_name: str) -> List[str]:\n",
    "    \"\"\"This is a method to give you a random movements list of a certain pokemon if the user asks for them\n",
    "\n",
    "    Args:\n",
    "        pokemon_name: a pokemon name given by the user.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Calling the tool random_movements to {pokemon_name.lower()}\")\n",
    "\n",
    "    # The url of the api\n",
    "    url = f'https://pokeapi.co/api/v2/pokemon/{pokemon_name.lower()}'\n",
    "        \n",
    "    # Make the API request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        raise ToolException(f\"Error: {pokemon_name} is not a valid pokemon\")\n",
    "\n",
    "    # Parse the response JSON\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the list of moves using map and lambda\n",
    "    moves = list(map(lambda move: move['move']['name'], data['moves']))\n",
    "\n",
    "    if len(moves) < 4:\n",
    "        return moves\n",
    "\n",
    "    # Select 4 random\n",
    "    selected_moves = random.sample(moves, 4)\n",
    "\n",
    "    return selected_moves"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
